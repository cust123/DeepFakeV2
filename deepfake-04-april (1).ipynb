{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UUGfjh_4dUS6",
    "outputId": "6b13ffa9-7815-43c3-efed-1c977f42a80f",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import kagglehub\n",
    "\n",
    "# Download the deepfake dataset from Kaggle\n",
    "path = kagglehub.dataset_download(\"aryansingh16/deepfake-dataset\")\n",
    "print(\"Path to dataset files:\", path)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-04T05:40:26.270222Z",
     "iopub.status.busy": "2025-04-04T05:40:26.270005Z",
     "iopub.status.idle": "2025-04-04T05:40:26.273748Z",
     "shell.execute_reply": "2025-04-04T05:40:26.272883Z",
     "shell.execute_reply.started": "2025-04-04T05:40:26.270200Z"
    },
    "id": "1p8_MAVwee0l",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# !unzip -q {path} -d /content/real_vs_fake"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AtFJD3IuBXGu"
   },
   "source": [
    "# Checking the Downloaded Dataset Files\n",
    "\n",
    "# Ensures that the dataset downloaded correctly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-04T05:40:26.274742Z",
     "iopub.status.busy": "2025-04-04T05:40:26.274389Z",
     "iopub.status.idle": "2025-04-04T05:40:26.301686Z",
     "shell.execute_reply": "2025-04-04T05:40:26.300939Z",
     "shell.execute_reply.started": "2025-04-04T05:40:26.274713Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contents of the dataset directory:\n",
      "['real_vs_fake']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "dataset_path = \"/kaggle/input/deepfake-dataset\"\n",
    "print(\"Contents of the dataset directory:\")\n",
    "print(os.listdir(dataset_path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-04-04T05:40:26.302723Z",
     "iopub.status.busy": "2025-04-04T05:40:26.302501Z",
     "iopub.status.idle": "2025-04-04T05:40:26.311403Z",
     "shell.execute_reply": "2025-04-04T05:40:26.310644Z",
     "shell.execute_reply.started": "2025-04-04T05:40:26.302694Z"
    },
    "id": "4-7C0_ckf1v1",
    "outputId": "f009ccff-8375-4755-9e2a-20925d970c15",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contents of real_vs_fake:\n",
      "['real-vs-fake']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "dataset_path = \"/kaggle/input/deepfake-dataset/real_vs_fake\"\n",
    "\n",
    "# List the contents of the dataset\n",
    "print(\"Contents of real_vs_fake:\")\n",
    "print(os.listdir(dataset_path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-04-04T05:40:26.313379Z",
     "iopub.status.busy": "2025-04-04T05:40:26.313195Z",
     "iopub.status.idle": "2025-04-04T05:40:26.331819Z",
     "shell.execute_reply": "2025-04-04T05:40:26.331129Z",
     "shell.execute_reply.started": "2025-04-04T05:40:26.313363Z"
    },
    "id": "2dcvep2ogFFH",
    "outputId": "397420bb-4c79-4cef-a224-7d736d8550ae",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contents of 'real-vs-fake':\n",
      "['valid', 'test', 'train']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Define the path to the 'real-vs-fake' directory\n",
    "real_vs_fake_path = os.path.join(dataset_path, 'real-vs-fake')\n",
    "\n",
    "# List the contents of the 'real-vs-fake' directory\n",
    "print(\"Contents of 'real-vs-fake':\")\n",
    "print(os.listdir(real_vs_fake_path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-04-04T05:40:26.332783Z",
     "iopub.status.busy": "2025-04-04T05:40:26.332555Z",
     "iopub.status.idle": "2025-04-04T05:40:26.369368Z",
     "shell.execute_reply": "2025-04-04T05:40:26.368260Z",
     "shell.execute_reply.started": "2025-04-04T05:40:26.332761Z"
    },
    "id": "KPqRP4PTgOUY",
    "outputId": "7173f2fd-8eb5-4e5f-faf2-01ea4aaf56ce",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contents of 'train' directory:\n",
      "['fake', 'real']\n",
      "\n",
      "Contents of 'valid' directory:\n",
      "['fake', 'real']\n",
      "\n",
      "Contents of 'test' directory:\n",
      "['fake', 'real']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Define the path to the 'real-vs-fake' directory\n",
    "real_vs_fake_path = \"/kaggle/input/deepfake-dataset/real_vs_fake/real-vs-fake\"\n",
    "\n",
    "# This loops through the three dataset folders: train, valid, and test.\n",
    "for split in ['train', 'valid', 'test']:\n",
    "    #dynamically creates the path to each folder.\n",
    "    split_path = os.path.join(real_vs_fake_path, split)\n",
    "    print(f\"Contents of '{split}' directory:\")\n",
    "    print(os.listdir(split_path))\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-04-04T05:40:26.370660Z",
     "iopub.status.busy": "2025-04-04T05:40:26.370426Z",
     "iopub.status.idle": "2025-04-04T05:40:39.157925Z",
     "shell.execute_reply": "2025-04-04T05:40:39.156930Z",
     "shell.execute_reply.started": "2025-04-04T05:40:26.370639Z"
    },
    "id": "2xoJB-bHgh99",
    "outputId": "6e486714-de23-498e-b3bb-3578ed2817ab",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported and dataset path set.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# For numerical operations\n",
    "import numpy as np\n",
    "#deep learning framework ,  for building and training neural networks.\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# Define dataset path, stores the dataset's location\n",
    "DATASET_PATH = \"/kaggle/input/deepfake-dataset/real_vs_fake/real-vs-fake\"\n",
    "\n",
    "print(\"Libraries imported and dataset path set.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-04-04T05:40:39.159245Z",
     "iopub.status.busy": "2025-04-04T05:40:39.158786Z",
     "iopub.status.idle": "2025-04-04T05:40:39.228223Z",
     "shell.execute_reply": "2025-04-04T05:40:39.227395Z",
     "shell.execute_reply.started": "2025-04-04T05:40:39.159221Z"
    },
    "id": "-cdp-H8Dguax",
    "outputId": "0a02990c-a6cb-41a1-90b9-b8d93cc91ce4",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Data augmentation and rescaling defined.\n"
     ]
    }
   ],
   "source": [
    "# Define image size and batch size\n",
    "IMG_SIZE = (224, 224)\n",
    "BATCH_SIZE = 32 # loading and processing 32 image at one time for processing, to optimize the memory\n",
    "\n",
    "# Data Augmentation for training images (  prevent overfitting by generating more diverse training samples.)\n",
    "train_datagen = keras.preprocessing.image.ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "# Validation & Test ( only rescaling)\n",
    "valid_test_datagen = keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "print(\" Data augmentation and rescaling defined.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-04-04T05:40:39.229251Z",
     "iopub.status.busy": "2025-04-04T05:40:39.229021Z",
     "iopub.status.idle": "2025-04-04T05:46:13.121980Z",
     "shell.execute_reply": "2025-04-04T05:46:13.121193Z",
     "shell.execute_reply.started": "2025-04-04T05:40:39.229231Z"
    },
    "id": "RXxhc4xHg24V",
    "outputId": "1e050131-dffc-4af6-fcc4-2837753afba4",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 102041 images belonging to 2 classes.\n",
      "Found 20000 images belonging to 2 classes.\n",
      "Found 20000 images belonging to 2 classes.\n",
      "Data generators are ready.\n"
     ]
    }
   ],
   "source": [
    "# Loading and Preparing Dataset for Deepfake Detection\n",
    "\n",
    "# Define dataset paths\n",
    "train_dir = os.path.join(dataset_path, \"real-vs-fake\", \"train\")\n",
    "valid_dir = os.path.join(dataset_path, \"real-vs-fake\", \"valid\")\n",
    "test_dir = os.path.join(dataset_path, \"real-vs-fake\", \"test\")\n",
    "\n",
    "# Create training generator\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='binary'\n",
    ")\n",
    "\n",
    "# Create validation generator\n",
    "valid_generator = valid_test_datagen.flow_from_directory(\n",
    "    valid_dir,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='binary'\n",
    ")\n",
    "\n",
    "# Create test generator\n",
    "test_generator = valid_test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='binary',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "print(\"Data generators are ready.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3mC485Rvg-rF"
   },
   "source": [
    "# **Build the Model Using EfficientNetB3 Backbone**\n",
    "\n",
    "Now, let's define the CNN model using EfficientNetB3 as the backbone for feature extraction, with a dropout layer for regularization and a final fully connected layer for binary classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-04-04T05:46:13.123273Z",
     "iopub.status.busy": "2025-04-04T05:46:13.122947Z",
     "iopub.status.idle": "2025-04-04T05:46:17.978687Z",
     "shell.execute_reply": "2025-04-04T05:46:17.977856Z",
     "shell.execute_reply.started": "2025-04-04T05:46:13.123240Z"
    },
    "id": "GpK7q7dwhDcB",
    "outputId": "63ac1e68-c2f1-49a0-84d9-d4ded3facae6",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb3_notop.h5\n",
      "\u001b[1m43941136/43941136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
      "Model built and compiled.\n"
     ]
    }
   ],
   "source": [
    "# Build the model with EfficientNetB3 backbone\n",
    "base_model = keras.applications.EfficientNetB3(\n",
    "    include_top=False,\n",
    "    weights='imagenet',  # Use ImageNet weights for transfer learning\n",
    "    input_shape=(IMG_SIZE[0], IMG_SIZE[1], 3)\n",
    ")\n",
    "\n",
    "# Freeze the base model initially to avoid training the weights during the first phase training\n",
    "base_model.trainable = False\n",
    "\n",
    "# Build the top layers for the model\n",
    "inputs = keras.Input(shape=(IMG_SIZE[0], IMG_SIZE[1], 3))\n",
    "x = keras.applications.efficientnet.preprocess_input(inputs)\n",
    "x = base_model(x, training=False)\n",
    "x = keras.layers.GlobalAveragePooling2D()(x)\n",
    "x = keras.layers.Dropout(0.5)(x)\n",
    "outputs = keras.layers.Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "# Create the complete model\n",
    "model = keras.Model(inputs, outputs)\n",
    "\n",
    "# Compile the model with Adam optimizer\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=1e-4),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "print(\"Model built and compiled.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CHelyIn7hUWo"
   },
   "source": [
    "# **Define Callbacks for Model Training**\n",
    "\n",
    "Now, let's define the callbacks that will be used during training to save the best model, reduce the learning rate, and stop early if needed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-04-04T05:46:17.981310Z",
     "iopub.status.busy": "2025-04-04T05:46:17.981065Z",
     "iopub.status.idle": "2025-04-04T05:46:17.986766Z",
     "shell.execute_reply": "2025-04-04T05:46:17.985887Z",
     "shell.execute_reply.started": "2025-04-04T05:46:17.981289Z"
    },
    "id": "UDolUFBJheEQ",
    "outputId": "e7c1f22f-8977-4888-e328-6cf57366b6a2",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Callbacks defined.\n"
     ]
    }
   ],
   "source": [
    "# Define the path to save the best model\n",
    "checkpoint_path = \"best_model.keras\"\n",
    "\n",
    "# ModelCheckpoint: Save the best model based on validation accuracy\n",
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\n",
    "    checkpoint_path,\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    "    save_best_only=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# ReduceLROnPlateau: Reduce learning rate if validation loss stops improving\n",
    "reduce_lr_cb = keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.5,\n",
    "    patience=2,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# EarlyStopping: Stop training if validation loss stops improving\n",
    "early_stop_cb = keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=2,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# CSVLogger: Log training history to a CSV file\n",
    "csv_logger = keras.callbacks.CSVLogger(\"training_log.csv\", append=True)\n",
    "\n",
    "print(\"Callbacks defined.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-04-04T05:46:17.990563Z",
     "iopub.status.busy": "2025-04-04T05:46:17.990310Z",
     "iopub.status.idle": "2025-04-04T05:46:18.004664Z",
     "shell.execute_reply": "2025-04-04T05:46:18.003973Z",
     "shell.execute_reply.started": "2025-04-04T05:46:17.990543Z"
    },
    "id": "g4dhCuGlixs_",
    "outputId": "32c90f27-eb49-48ee-9309-45dbc3d5b3ea",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: /device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "print(\"Using device:\", tf.test.gpu_device_name())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qqFi0XxjhopS"
   },
   "source": [
    "# **Train the Model**\n",
    "\n",
    "Now, let's train the model using the defined callbacks, data generators, and model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-04-04T05:46:18.005707Z",
     "iopub.status.busy": "2025-04-04T05:46:18.005450Z",
     "iopub.status.idle": "2025-04-04T07:37:07.097849Z",
     "shell.execute_reply": "2025-04-04T07:37:07.097051Z",
     "shell.execute_reply.started": "2025-04-04T05:46:18.005674Z"
    },
    "id": "vX196-IIhu3_",
    "outputId": "a76d8c6d-9210-4f5d-ff70-40482e8cc547",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3189/3189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 696ms/step - accuracy: 0.4994 - loss: 0.7006\n",
      "Epoch 1: val_accuracy improved from -inf to 0.50000, saving model to best_model.keras\n",
      "\u001b[1m3189/3189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2496s\u001b[0m 770ms/step - accuracy: 0.4994 - loss: 0.7006 - val_accuracy: 0.5000 - val_loss: 0.6938 - learning_rate: 1.0000e-04\n",
      "Epoch 2/4\n",
      "\u001b[1m3189/3189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 408ms/step - accuracy: 0.5020 - loss: 0.6983\n",
      "Epoch 2: val_accuracy improved from 0.50000 to 0.50010, saving model to best_model.keras\n",
      "\u001b[1m3189/3189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1390s\u001b[0m 435ms/step - accuracy: 0.5020 - loss: 0.6983 - val_accuracy: 0.5001 - val_loss: 0.6931 - learning_rate: 1.0000e-04\n",
      "Epoch 3/4\n",
      "\u001b[1m3189/3189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 425ms/step - accuracy: 0.4983 - loss: 0.6975\n",
      "Epoch 3: val_accuracy improved from 0.50010 to 0.52150, saving model to best_model.keras\n",
      "\u001b[1m3189/3189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1426s\u001b[0m 446ms/step - accuracy: 0.4983 - loss: 0.6975 - val_accuracy: 0.5215 - val_loss: 0.6929 - learning_rate: 1.0000e-04\n",
      "Epoch 4/4\n",
      "\u001b[1m3189/3189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 400ms/step - accuracy: 0.5007 - loss: 0.6963\n",
      "Epoch 4: val_accuracy did not improve from 0.52150\n",
      "\u001b[1m3189/3189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1335s\u001b[0m 418ms/step - accuracy: 0.5007 - loss: 0.6963 - val_accuracy: 0.5000 - val_loss: 0.6933 - learning_rate: 1.0000e-04\n",
      "Restoring model weights from the end of the best epoch: 3.\n",
      " Training complete!\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "epochs = 4\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=valid_generator,\n",
    "    epochs=epochs,\n",
    "    callbacks=[checkpoint_cb, reduce_lr_cb, early_stop_cb, csv_logger]\n",
    ")\n",
    "\n",
    "print(\" Training complete!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yg1Ll6zjDIsE"
   },
   "source": [
    "# Unfreeze Base Model for Fine-Tuning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-04-04T07:37:07.099386Z",
     "iopub.status.busy": "2025-04-04T07:37:07.098814Z",
     "iopub.status.idle": "2025-04-04T07:37:07.114109Z",
     "shell.execute_reply": "2025-04-04T07:37:07.113416Z",
     "shell.execute_reply.started": "2025-04-04T07:37:07.099362Z"
    },
    "id": "ixcGsZrLDKxC",
    "outputId": "aaa9b014-afa7-4e82-e059-87351c252469",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base model unfrozen and recompiled.\n"
     ]
    }
   ],
   "source": [
    "# Unfreeze the base model\n",
    "base_model.trainable = True\n",
    "\n",
    "# Recompile the model with a lower learning rate\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=1e-5),  # Reduced LR\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "print(\"Base model unfrozen and recompiled.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UraK3iJyEuMx"
   },
   "source": [
    "# Adjust Data Augmentation\n",
    "\n",
    "Add more aggressive augmentation to handle subtle deepfake artifacts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-04T07:37:07.115350Z",
     "iopub.status.busy": "2025-04-04T07:37:07.115077Z",
     "iopub.status.idle": "2025-04-04T07:37:07.127220Z",
     "shell.execute_reply": "2025-04-04T07:37:07.126459Z",
     "shell.execute_reply.started": "2025-04-04T07:37:07.115317Z"
    },
    "id": "15L0ZqgOEvJS",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_datagen = keras.preprocessing.image.ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.3,\n",
    "    horizontal_flip=True,\n",
    "    brightness_range=[0.7, 1.3],  #  brightness\n",
    "    fill_mode='nearest'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0J6BHSkIFBBQ"
   },
   "source": [
    "# Class Balance Check\n",
    "\n",
    "Add class weights if there’s an imbalance:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-04-04T07:37:07.128279Z",
     "iopub.status.busy": "2025-04-04T07:37:07.128059Z",
     "iopub.status.idle": "2025-04-04T07:37:07.163619Z",
     "shell.execute_reply": "2025-04-04T07:37:07.162996Z",
     "shell.execute_reply.started": "2025-04-04T07:37:07.128260Z"
    },
    "id": "m4UmC2pXFC1X",
    "outputId": "b897a575-b0ed-4fc3-beb2-e4b59b32fe48",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class weights: {0: 1.997631213171238, 1: 2.002374411302983}\n"
     ]
    }
   ],
   "source": [
    "# Calculate class weights (example: if fake = 60%, real = 40%)\n",
    "import numpy as np\n",
    "\n",
    "class_counts = np.array([len(os.listdir(os.path.join(train_dir, 'real'))),\n",
    "                         len(os.listdir(os.path.join(train_dir, 'fake')))])\n",
    "total = class_counts.sum()\n",
    "class_weights = {0: total/class_counts[0], 1: total/class_counts[1]}\n",
    "print(\"Class weights:\", class_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UP0D7PsQFIxp"
   },
   "source": [
    "# Train with Fine-Tuning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-04-04T07:37:07.164618Z",
     "iopub.status.busy": "2025-04-04T07:37:07.164338Z",
     "iopub.status.idle": "2025-04-04T08:52:44.577948Z",
     "shell.execute_reply": "2025-04-04T08:52:44.577109Z",
     "shell.execute_reply.started": "2025-04-04T07:37:07.164588Z"
    },
    "id": "71b0wUF0FJiQ",
    "outputId": "cd09e788-9a36-4d0f-f95e-c595f73f72fa",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/6\n",
      "\u001b[1m3189/3189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 431ms/step - accuracy: 0.7246 - loss: 1.0390\n",
      "Epoch 4: val_accuracy improved from 0.52150 to 0.91485, saving model to best_model.keras\n",
      "\u001b[1m3189/3189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1563s\u001b[0m 455ms/step - accuracy: 0.7246 - loss: 1.0389 - val_accuracy: 0.9148 - val_loss: 0.2145 - learning_rate: 1.0000e-05\n",
      "Epoch 5/6\n",
      "\u001b[1m3189/3189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 420ms/step - accuracy: 0.9194 - loss: 0.4071\n",
      "Epoch 5: val_accuracy improved from 0.91485 to 0.95365, saving model to best_model.keras\n",
      "\u001b[1m3189/3189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1418s\u001b[0m 444ms/step - accuracy: 0.9194 - loss: 0.4071 - val_accuracy: 0.9536 - val_loss: 0.1242 - learning_rate: 1.0000e-05\n",
      "Epoch 6/6\n",
      "\u001b[1m3189/3189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 466ms/step - accuracy: 0.9501 - loss: 0.2681\n",
      "Epoch 6: val_accuracy improved from 0.95365 to 0.96880, saving model to best_model.keras\n",
      "\u001b[1m3189/3189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1555s\u001b[0m 487ms/step - accuracy: 0.9501 - loss: 0.2681 - val_accuracy: 0.9688 - val_loss: 0.0856 - learning_rate: 1.0000e-05\n",
      "Restoring model weights from the end of the best epoch: 6.\n"
     ]
    }
   ],
   "source": [
    "# Continue training with unfrozen layers\n",
    "fine_tune_epochs = 4\n",
    "total_epochs =2+fine_tune_epochs\n",
    "\n",
    "history_fine = model.fit(\n",
    "    train_generator,\n",
    "    epochs=total_epochs,\n",
    "    initial_epoch=history.epoch[-1],  # Start from last epoch\n",
    "    validation_data=valid_generator,\n",
    "    callbacks=[checkpoint_cb, reduce_lr_cb, early_stop_cb, csv_logger],\n",
    "    class_weight=class_weights  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-04T08:52:44.579251Z",
     "iopub.status.busy": "2025-04-04T08:52:44.579032Z",
     "iopub.status.idle": "2025-04-04T08:52:45.934183Z",
     "shell.execute_reply": "2025-04-04T08:52:45.933521Z",
     "shell.execute_reply.started": "2025-04-04T08:52:44.579232Z"
    },
    "id": "cQFGeQNZqvKI",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model.save('my_deepfake_model_with_fine_tuning_04_April.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-04T08:52:45.935160Z",
     "iopub.status.busy": "2025-04-04T08:52:45.934925Z",
     "iopub.status.idle": "2025-04-04T08:52:45.940945Z",
     "shell.execute_reply": "2025-04-04T08:52:45.940229Z",
     "shell.execute_reply.started": "2025-04-04T08:52:45.935140Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='my_deepfake_model_with_fine_tuning_04_April.keras' target='_blank'>my_deepfake_model_with_fine_tuning_04_April.keras</a><br>"
      ],
      "text/plain": [
       "/kaggle/working/my_deepfake_model_with_fine_tuning_04_April.keras"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import FileLink\n",
    "FileLink(r'my_deepfake_model_with_fine_tuning_04_April.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-04T08:52:45.942040Z",
     "iopub.status.busy": "2025-04-04T08:52:45.941782Z",
     "iopub.status.idle": "2025-04-04T08:52:47.192843Z",
     "shell.execute_reply": "2025-04-04T08:52:47.191981Z",
     "shell.execute_reply.started": "2025-04-04T08:52:45.942015Z"
    },
    "id": "dm4QwqgpudUd",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#ew imports\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from tensorflow.keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-04T08:52:47.196455Z",
     "iopub.status.busy": "2025-04-04T08:52:47.195941Z",
     "iopub.status.idle": "2025-04-04T08:52:47.203848Z",
     "shell.execute_reply": "2025-04-04T08:52:47.203040Z",
     "shell.execute_reply.started": "2025-04-04T08:52:47.196424Z"
    },
    "id": "MchQKZGEv_DF",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Custom F1 Score metric\n",
    "class F1Score(tf.keras.metrics.Metric):\n",
    "    def __init__(self, name='f1_score', **kwargs):\n",
    "        super().__init__(name=name, **kwargs)\n",
    "        self.precision = tf.keras.metrics.Precision()\n",
    "        self.recall = tf.keras.metrics.Recall()\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        self.precision.update_state(y_true, y_pred)\n",
    "        self.recall.update_state(y_true, y_pred)\n",
    "\n",
    "    def result(self):\n",
    "        p = self.precision.result()\n",
    "        r = self.recall.result()\n",
    "        return 2 * ((p * r) / (p + r + K.epsilon()))\n",
    "\n",
    "    def reset_states(self):\n",
    "        self.precision.reset_states()\n",
    "        self.recall.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-04T08:52:47.205479Z",
     "iopub.status.busy": "2025-04-04T08:52:47.205253Z",
     "iopub.status.idle": "2025-04-04T08:52:47.234541Z",
     "shell.execute_reply": "2025-04-04T08:52:47.233979Z",
     "shell.execute_reply.started": "2025-04-04T08:52:47.205460Z"
    },
    "id": "YlXYzMMWwFf6",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def compile_model(model):\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=1e-5),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=[\n",
    "            'accuracy',\n",
    "            tf.keras.metrics.Precision(name='precision'),\n",
    "            tf.keras.metrics.Recall(name='recall'),\n",
    "            F1Score()\n",
    "        ]\n",
    "    )\n",
    "\n",
    "\n",
    "compile_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-04-04T08:52:47.235483Z",
     "iopub.status.busy": "2025-04-04T08:52:47.235273Z",
     "iopub.status.idle": "2025-04-04T08:59:07.448241Z",
     "shell.execute_reply": "2025-04-04T08:59:07.447332Z",
     "shell.execute_reply.started": "2025-04-04T08:52:47.235453Z"
    },
    "id": "itDE82z7wHEM",
    "outputId": "86d5044a-98f6-4dd4-c07a-941e52021ed4",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Evaluation:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 308ms/step\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Real       0.95      0.99      0.97     10000\n",
      "        Fake       0.99      0.94      0.97     10000\n",
      "\n",
      "    accuracy                           0.97     20000\n",
      "   macro avg       0.97      0.97      0.97     20000\n",
      "weighted avg       0.97      0.97      0.97     20000\n",
      "\n",
      "Confusion Matrix:\n",
      "[[9939   61]\n",
      " [ 575 9425]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def evaluate_model(model, test_generator):\n",
    "    # Generate predictions\n",
    "    y_pred = model.predict(test_generator)\n",
    "    y_pred = (y_pred > 0.5).astype(int)\n",
    "\n",
    "    # Get true labels\n",
    "    y_true = test_generator.classes\n",
    "\n",
    "    # Classification report\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_true, y_pred, target_names=['Real', 'Fake']))\n",
    "\n",
    "    # Confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(cm)\n",
    "\n",
    "    # Visual metrics\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    metrics = ['accuracy', 'precision', 'recall', 'f1_score']\n",
    "    values = [model.evaluate(test_generator, verbose=0)[i+1] for i in range(4)]\n",
    "    plt.bar(metrics, values)\n",
    "    plt.title('Test Metrics')\n",
    "    plt.ylim(0, 1)\n",
    "    plt.show()\n",
    "\n",
    "#after training\n",
    "print(\"\\nFinal Evaluation:\")\n",
    "evaluate_model(model, test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-04T08:59:07.449645Z",
     "iopub.status.busy": "2025-04-04T08:59:07.449325Z",
     "iopub.status.idle": "2025-04-04T08:59:07.455100Z",
     "shell.execute_reply": "2025-04-04T08:59:07.454209Z",
     "shell.execute_reply.started": "2025-04-04T08:59:07.449613Z"
    },
    "id": "OW-4NErRwSQV",
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'def make_gradcam_heatmap(img_array, model, last_conv_layer_name=\\'top_conv\\'):\\n    grad_model = tf.keras.models.Model(\\n        [model.inputs], [model.get_layer(last_conv_layer_name).output, model.output]\\n    )\\n\\n    with tf.GradientTape() as tape:\\n        conv_outputs, predictions = grad_model(img_array)\\n        loss = predictions[:, 0]  # For binary classification\\n\\n    grads = tape.gradient(loss, conv_outputs)\\n    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\\n\\n    heatmap = tf.reduce_mean(tf.multiply(pooled_grads, conv_outputs), axis=-1)\\n    heatmap = np.maximum(heatmap, 0)\\n    heatmap /= np.max(heatmap)\\n    return heatmap[0]\\n\\ndef visualize_explanations(test_generator, model, num_samples=3):\\n    images, labels = next(test_generator)\\n\\n    plt.figure(figsize=(15, 5))\\n    for i in range(num_samples):\\n        img_array = np.expand_dims(images[i], axis=0)\\n        heatmap = make_gradcam_heatmap(img_array, model)\\n\\n        # Resize and create overlay\\n        heatmap = cv2.resize(heatmap, (224, 224))\\n        heatmap = np.uint8(255 * heatmap)\\n        heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\\n        superimposed_img = heatmap * 0.4 + images[i] * 0.6\\n\\n        plt.subplot(1, num_samples, i+1)\\n        plt.imshow(superimposed_img.astype(\\'uint8\\'))\\n        plt.title(f\"True: {\\'Real\\' if labels[i]==0 else \\'Fake\\'}\\nPred: {model.predict(img_array)[0][0]:.2f}\")\\n        plt.axis(\\'off\\')\\n    plt.show()\\n\\n# Run after evaluation\\nprint(\"\\nSample Explanations:\")\\nvisualize_explanations(test_generator, model)\\n'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"def make_gradcam_heatmap(img_array, model, last_conv_layer_name='top_conv'):\n",
    "    grad_model = tf.keras.models.Model(\n",
    "        [model.inputs], [model.get_layer(last_conv_layer_name).output, model.output]\n",
    "    )\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        conv_outputs, predictions = grad_model(img_array)\n",
    "        loss = predictions[:, 0]  # For binary classification\n",
    "\n",
    "    grads = tape.gradient(loss, conv_outputs)\n",
    "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
    "\n",
    "    heatmap = tf.reduce_mean(tf.multiply(pooled_grads, conv_outputs), axis=-1)\n",
    "    heatmap = np.maximum(heatmap, 0)\n",
    "    heatmap /= np.max(heatmap)\n",
    "    return heatmap[0]\n",
    "\n",
    "def visualize_explanations(test_generator, model, num_samples=3):\n",
    "    images, labels = next(test_generator)\n",
    "\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    for i in range(num_samples):\n",
    "        img_array = np.expand_dims(images[i], axis=0)\n",
    "        heatmap = make_gradcam_heatmap(img_array, model)\n",
    "\n",
    "        # Resize and create overlay\n",
    "        heatmap = cv2.resize(heatmap, (224, 224))\n",
    "        heatmap = np.uint8(255 * heatmap)\n",
    "        heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
    "        superimposed_img = heatmap * 0.4 + images[i] * 0.6\n",
    "\n",
    "        plt.subplot(1, num_samples, i+1)\n",
    "        plt.imshow(superimposed_img.astype('uint8'))\n",
    "        plt.title(f\"True: {'Real' if labels[i]==0 else 'Fake'}\\nPred: {model.predict(img_array)[0][0]:.2f}\")\n",
    "        plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# Run after evaluation\n",
    "print(\"\\nSample Explanations:\")\n",
    "visualize_explanations(test_generator, model)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-04T08:59:07.456136Z",
     "iopub.status.busy": "2025-04-04T08:59:07.455822Z",
     "iopub.status.idle": "2025-04-04T08:59:08.215524Z",
     "shell.execute_reply": "2025-04-04T08:59:08.214832Z",
     "shell.execute_reply.started": "2025-04-04T08:59:07.456106Z"
    },
    "id": "BreGQbBzwvgu",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# After all training and evaluation\n",
    "model.save('my_deepfake_model_with_fine_tuning_04_April_part2.keras')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-04T08:59:08.216450Z",
     "iopub.status.busy": "2025-04-04T08:59:08.216247Z",
     "iopub.status.idle": "2025-04-04T08:59:08.221367Z",
     "shell.execute_reply": "2025-04-04T08:59:08.220591Z",
     "shell.execute_reply.started": "2025-04-04T08:59:08.216432Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='my_deepfake_model_with_fine_tuning_04_April_part2.keras' target='_blank'>my_deepfake_model_with_fine_tuning_04_April_part2.keras</a><br>"
      ],
      "text/plain": [
       "/kaggle/working/my_deepfake_model_with_fine_tuning_04_April_part2.keras"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import FileLink\n",
    "FileLink(r'my_deepfake_model_with_fine_tuning_04_April_part2.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-04T08:59:08.222673Z",
     "iopub.status.busy": "2025-04-04T08:59:08.222355Z",
     "iopub.status.idle": "2025-04-04T08:59:08.234238Z",
     "shell.execute_reply": "2025-04-04T08:59:08.233521Z",
     "shell.execute_reply.started": "2025-04-04T08:59:08.222633Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def preprocess_image(image_path, target_size=(224, 224)):\n",
    "    img = cv2.imread(image_path)\n",
    "    if img is None:\n",
    "        raise FileNotFoundError(f\"Error: Unable to load image at {image_path}\")\n",
    "\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  \n",
    "    img = cv2.resize(img, target_size) \n",
    "    img = img.astype('float32') / 255.0  \n",
    "    img = np.expand_dims(img, axis=0)  \n",
    "    return img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-04T08:59:08.235272Z",
     "iopub.status.busy": "2025-04-04T08:59:08.234986Z",
     "iopub.status.idle": "2025-04-04T08:59:18.221235Z",
     "shell.execute_reply": "2025-04-04T08:59:18.220396Z",
     "shell.execute_reply.started": "2025-04-04T08:59:08.235241Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10s/step\n",
      "Prediction: Real\n",
      "Confidence Score: 0.9878\n"
     ]
    }
   ],
   "source": [
    "image_path2 = '/kaggle/input/deepfake-dataset/real_vs_fake/real-vs-fake/test/real/00007.jpg' \n",
    "input_image = preprocess_image(image_path2)\n",
    "prediction = model.predict(input_image)\n",
    "\n",
    "threshold = 0.6 \n",
    "if prediction[0][0] < threshold:\n",
    "    print(\"Prediction: Fake\")\n",
    "else:\n",
    "    print(\"Prediction: Real\")\n",
    "\n",
    "print(f\"Confidence Score: {prediction[0][0]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-04T08:59:18.222577Z",
     "iopub.status.busy": "2025-04-04T08:59:18.222250Z",
     "iopub.status.idle": "2025-04-04T08:59:18.294863Z",
     "shell.execute_reply": "2025-04-04T08:59:18.294224Z",
     "shell.execute_reply.started": "2025-04-04T08:59:18.222543Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "Prediction: Fake\n",
      "Confidence Score: 0.0589\n"
     ]
    }
   ],
   "source": [
    "image_path3 = '/kaggle/input/deepfake-dataset/real_vs_fake/real-vs-fake/test/fake/00276TOPP4.jpg' \n",
    "input_image3 = preprocess_image(image_path3)\n",
    "prediction3 = model.predict(input_image3)\n",
    "\n",
    "threshold = 0.6 \n",
    "if prediction3[0][0] < threshold:\n",
    "    print(\"Prediction: Fake\")\n",
    "else:\n",
    "    print(\"Prediction: Real\")\n",
    "\n",
    "print(f\"Confidence Score: {prediction3[0][0]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-04T08:59:18.295722Z",
     "iopub.status.busy": "2025-04-04T08:59:18.295524Z",
     "iopub.status.idle": "2025-04-04T08:59:18.362696Z",
     "shell.execute_reply": "2025-04-04T08:59:18.362063Z",
     "shell.execute_reply.started": "2025-04-04T08:59:18.295705Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "Prediction: Fake\n",
      "Confidence Score: 0.0001\n"
     ]
    }
   ],
   "source": [
    "image_path4 = '/kaggle/input/deepfake-dataset/real_vs_fake/real-vs-fake/test/fake/00KEKJJ1Q4.jpg' \n",
    "input_image4 = preprocess_image(image_path4)\n",
    "prediction4 = model.predict(input_image4)\n",
    "\n",
    "threshold = 0.6 \n",
    "if prediction4[0][0] < threshold:\n",
    "    print(\"Prediction: Fake\")\n",
    "else:\n",
    "    print(\"Prediction: Real\")\n",
    "\n",
    "print(f\"Confidence Score: {prediction4[0][0]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-04T09:07:36.211247Z",
     "iopub.status.busy": "2025-04-04T09:07:36.210851Z",
     "iopub.status.idle": "2025-04-04T09:07:36.216785Z",
     "shell.execute_reply": "2025-04-04T09:07:36.215830Z",
     "shell.execute_reply.started": "2025-04-04T09:07:36.211218Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='best_model.keras' target='_blank'>best_model.keras</a><br>"
      ],
      "text/plain": [
       "/kaggle/working/best_model.keras"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import FileLink\n",
    "FileLink(r'best_model.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-04T09:16:57.640417Z",
     "iopub.status.busy": "2025-04-04T09:16:57.639951Z",
     "iopub.status.idle": "2025-04-04T09:16:57.721291Z",
     "shell.execute_reply": "2025-04-04T09:16:57.720599Z",
     "shell.execute_reply.started": "2025-04-04T09:16:57.640389Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "Prediction 5: Real\n",
      "Confidence Score of 5th is: 0.9823\n"
     ]
    }
   ],
   "source": [
    "image_path5 = '/kaggle/input/deepfake-dataset/real_vs_fake/real-vs-fake/test/real/00104.jpg' \n",
    "input_image5 = preprocess_image(image_path5)\n",
    "prediction5 = model.predict(input_image5)\n",
    "\n",
    "threshold = 0.6 \n",
    "if prediction5[0][0] < threshold:\n",
    "    print(\"Prediction 5: Fake\")\n",
    "else:\n",
    "    print(\"Prediction 5: Real\")\n",
    "\n",
    "print(f\"Confidence Score of 5th is: {prediction5[0][0]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-04T09:20:14.443054Z",
     "iopub.status.busy": "2025-04-04T09:20:14.442650Z",
     "iopub.status.idle": "2025-04-04T09:20:14.566325Z",
     "shell.execute_reply": "2025-04-04T09:20:14.565413Z",
     "shell.execute_reply.started": "2025-04-04T09:20:14.443023Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "Prediction 6: Real\n",
      "Confidence Score of 6th is: 0.9847\n"
     ]
    }
   ],
   "source": [
    "image_path6 = '/kaggle/input/deepfake-dataset/real_vs_fake/real-vs-fake/test/real/00170.jpg' \n",
    "input_image6 = preprocess_image(image_path6)\n",
    "prediction6 = model.predict(input_image6)\n",
    "\n",
    "threshold = 0.6 \n",
    "if prediction6[0][0] < threshold:\n",
    "    print(\"Prediction 6: Fake\")\n",
    "else:\n",
    "    print(\"Prediction 6: Real\")\n",
    "\n",
    "print(f\"Confidence Score of 6th is: {prediction6[0][0]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-04T09:21:42.968704Z",
     "iopub.status.busy": "2025-04-04T09:21:42.968294Z",
     "iopub.status.idle": "2025-04-04T09:21:43.065960Z",
     "shell.execute_reply": "2025-04-04T09:21:43.065116Z",
     "shell.execute_reply.started": "2025-04-04T09:21:42.968673Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "Prediction 7: Fake\n",
      "Confidence Score of 7th is: 0.0036\n"
     ]
    }
   ],
   "source": [
    "image_path7 = '/kaggle/input/deepfake-dataset/real_vs_fake/real-vs-fake/test/fake/02YD6CVUGS.jpg' \n",
    "input_image7 = preprocess_image(image_path7)\n",
    "prediction7 = model.predict(input_image7)\n",
    "\n",
    "threshold = 0.6 \n",
    "if prediction7[0][0] < threshold:\n",
    "    print(\"Prediction 7: Fake\")\n",
    "else:\n",
    "    print(\"Prediction 7: Real\")\n",
    "\n",
    "print(f\"Confidence Score of 7th is: {prediction7[0][0]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-04T09:26:33.791875Z",
     "iopub.status.busy": "2025-04-04T09:26:33.791492Z",
     "iopub.status.idle": "2025-04-04T09:26:33.865633Z",
     "shell.execute_reply": "2025-04-04T09:26:33.864988Z",
     "shell.execute_reply.started": "2025-04-04T09:26:33.791843Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "Prediction 8: Fake\n",
      "Confidence Score of 8th is: 0.0000\n"
     ]
    }
   ],
   "source": [
    "image_path8 = '/kaggle/input/deepfake-dataset/real_vs_fake/real-vs-fake/test/fake/02XAKN4F4U.jpg' \n",
    "input_image8 = preprocess_image(image_path8)\n",
    "prediction8 = model.predict(input_image8)\n",
    "\n",
    "threshold = 0.6 \n",
    "if prediction8[0][0] < threshold:\n",
    "    print(\"Prediction 8: Fake\")\n",
    "else:\n",
    "    print(\"Prediction 8: Real\")\n",
    "\n",
    "print(f\"Confidence Score of 8th is: {prediction8[0][0]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-04T10:26:49.177122Z",
     "iopub.status.busy": "2025-04-04T10:26:49.176762Z",
     "iopub.status.idle": "2025-04-04T10:26:49.260721Z",
     "shell.execute_reply": "2025-04-04T10:26:49.260000Z",
     "shell.execute_reply.started": "2025-04-04T10:26:49.177091Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "Prediction 9: Fake\n",
      "Confidence Score of 9th is: 0.0024\n"
     ]
    }
   ],
   "source": [
    "image_path9 = '/kaggle/input/deepfake-dataset/real_vs_fake/real-vs-fake/test/fake/02TPLQKRQB.jpg' \n",
    "input_image9 = preprocess_image(image_path9)\n",
    "prediction9 = model.predict(input_image9)\n",
    "\n",
    "threshold = 0.6 \n",
    "if prediction9[0][0] < threshold:\n",
    "    print(\"Prediction 9: Fake\")\n",
    "else:\n",
    "    print(\"Prediction 9: Real\")\n",
    "\n",
    "print(f\"Confidence Score of 9th is: {prediction9[0][0]:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 4564185,
     "sourceId": 7796037,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6921583,
     "sourceId": 11103030,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6921611,
     "sourceId": 11103065,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
